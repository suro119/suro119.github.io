    <!-- Download Section -->
    <section id="projects" class="content-section text-center">
        <div class="projects-section">
            <div class="container">
                <div class="col-lg-8 col-lg-offset-2">
                    <h2>Projects</h2>
                    <!-- <a href="http://startbootstrap.com/template-overviews/grayscale/" class="btn btn-default btn-lg">Visit Download Page</a> -->
                </div>
                <div class="row">
                    <div class="col-lg-10 col-lg-offset-1 mb-10 project-container" id="ai-kitchen">
                        <h3>AI Recipe Navigation Demo</h3>
                        <div class="row">
                            <div class="col-lg-8 col-lg-offset-2">
                                <figure class="projects-fig">
                                    <img class="projects-img" src="img/projects/ai-kitchen.png" height="350"></img>
                                    <figcaption>AI Recipe Navigation</figcaption>
                                </figure>
                            </div>
                        </div>
                        <p>
                            At Samsung Research, I was responsible for integrating novel AI research from <em>Samsung AI Center - Toronto</em>, <em>Samsung AI Center - Cambridge</em>, and 
                            <em>Samsung Research</em> into an AI recipe navigation demo. The AI recipe navigation demo consisted of five modules:
                        </p>
                        <ol>
                            <li>an annotation server responsible for parsing recipe annotations</li>
                            <li>a main server responsible for temporally segmenting recipe videos, matching user query to a recipe caption, and returning the corresponding video segment</li>
                            <li>web client implemented with flask, svelte, bootstrap, and node.js that allows the user to query the model and displays model output by playing the corresponding video segment on YouTube.</li>
                            <li>an action recognition module that detects user action through a camera and sends a recipe query to the server</li>
                            <li>an automatic speech recognition module that allows the user to query the model through a microphone</li>
                        </ol>
                        <p>
                            gRPC, HTTP, and Mosquitto was used for communication between the different modules. This demo was part of the Samsung Research Open Lab 2022 exhibition.
                        </p>
                    </div>
                    <div class="col-lg-10 col-lg-offset-1 mb-10 project-container" id="deep-compression">
                        <h3>Content-Aware and Task-Aware Deep Image Compression</h3>
                        <div class="row">
                            <div class="col-lg-8 col-lg-offset-2">
                                <figure class="projects-fig">
                                    <img class="projects-img" src="img/projects/comp_inference.png" height="250"></img>
                                    <figcaption>Compressed Inference</figcaption>
                                </figure>
                            </div>
                        </div>
                        <p>
                            In this research, we focused on improving deep image compression networks by using content-aware networks and task-aware networks.
                            We tested content-aware performance using the CelebA dataset and tested task-aware performance using ImageNet. For task-awareness, we performed classification from the compressed code (as shown in the image above), which uses less storage and results in faster inference. To train this classification network, we used a parametrized joint loss consisting of a compression loss and a task loss.
                            Content-aware image compression achieved up to 2% improvement in terms of PSNR, and task-aware compression achieved up to 11% improvement in terms of accuracy for low resolution images.
                        </p>
                        <ul class="list-inline download-buttons">
                            <li>
                                <a href="files/urp1.pdf" target="_blank" class="btn btn-download btn-lg" download="research_paper_1.pdf"><i class="fa fa-file-pdf-o fa-fw"></i> <span class="file-name">PDF</span></a>
                            </li>
                            <li>
                                <a href="https://github.com/suro119/CAE" target="_blank" class="btn btn-download btn-lg"><i class="fa fa-github fa-fw"></i> <span class="file-name">Github</span></a>
                            </li>
                        </ul>
                    </div>
                    <div class="col-lg-10 col-lg-offset-1 mb-10 project-container" id="spi-inspection">
                        <h3>Deep Real-time Solder Paste Inspection</h3>
                        <div class="row">
                            <div class="col-lg-4">
                                <figure class="projects-fig">
                                    <img class="projects-img" src="img/projects/kafka_logo.svg" width="250"></img>
                                </figure>
                            </div>
                            <div class="col-lg-4">
                                <figure class="projects-fig">
                                    <img class="projects-img" src="img/projects/spark_logo.svg" width="250"></img>
                                </figure>
                            </div>
                            <div class="col-lg-4">
                                <figure class="projects-fig">
                                    <img class="projects-img" src="img/projects/hbase_logo.svg" width="250"></img>
                                </figure>
                            </div>
                        </div>
                        <p>During my internship at Koh Young Technology, I implemented a prototype for a distributed, real-time SMT (surface-mount technology) inspection process using Apache Sparkâ€™s Machine Learning Library. 
                            For efficient training and inference, I created and managed a distributed cluster for data streaming using Apache Kafka. Overall, I achieved up to 10x speed up from batch processing.</p>
                    </div>
                    <div class="col-lg-10 col-lg-offset-1 mb-10 project-container">
                        <h3>Hybrid Adaptive Ant Colony System for TSP</h3>
                        <div class="row">
                            <div class="col-lg-6 col-lg-offset-3">
                                <figure class="projects-fig">
                                    <img class="projects-img", src="img/projects/HAACS.jpg" width="350"></img>
                                </figure>
                            </div>
                        </div>
                        <p>As part of my <em>AI-based Software Engineering</em> course, I implemented a meta-heuristic solution for the traveling salesman problem by devising my own improved Ant Colony System (ACS) algorithm. 
                            The algorithm utilizes randomized local search to speed up convergence, and dynamically tunes ACS parameters to encourage exploration away from the local minima. My algorithm outperforms the two-opt algorithm and conventional ACS in terms of convergence speed, 
                            and removed the need to set experiment-specific parameters as required for convential ACS.</p>
                        <ul class="list-inline download-buttons">
                            <li>
                                <a href="files/haacs.pdf" target="_blank" class="btn btn-download btn-lg" download="haacs.pdf"><i class="fa fa-file-pdf-o fa-fw"></i> <span class="file-name">PDF</span></a>
                            </li>
                            <li>
                                <a href="https://github.com/suro119/HAACS" target="_blank" class="btn btn-download btn-lg"><i class="fa fa-github fa-fw"></i> <span class="file-name">Github</span></a>
                            </li>
                        </ul>
                    </div>
                    <div class="col-lg-10 col-lg-offset-1 mb-10 project-container" id="spi-inspection">
                        <h3>Masked Emotion Detection for COVID-19</h3>
                        <div class="row">
                            <div class="col-lg-12">
                                <figure class="projects-fig">
                                    <img class="projects-img", src="img/projects/masked_emotion.png" width="600"></img>
                                </figure>
                            </div>
                        </div>
                        <p>To enhance the emotion detection of people wearing masks during the COVID-19 crisis, we enhanced a baseline model, Deep Emotion, by training with natural and synthetic masked data along with architectural modifications to improve classification accuracy by 16%.</p>
                        <ul class="list-inline download-buttons">
                            <li>
                                <a href="files/masked_emotion.pdf" target="_blank" class="btn btn-download btn-lg" download="masked_emotion.pdf"><i class="fa fa-file-pdf-o fa-fw"></i> <span class="file-name">PDF</span></a>
                            </li>
                            <li>
                                <a href="https://github.com/Oh-yk/CS470_EmotionDetection" target="_blank" class="btn btn-download btn-lg"><i class="fa fa-github fa-fw"></i> <span class="file-name">Github</span></a>
                            </li>
                        </ul>
                    </div>
                    <div class="col-lg-10 col-lg-offset-1 mb-10 project-container">
                        <h3>Coreference Resolution using Python</h3>
                        <div class="row">
                            <div class="col-lg-12">
                                <figure class="projects-fig">
                                    <img class="projects-img", src="img/projects/NLP.png" width="800"></img>
                                </figure>
                            </div>
                        </div>
                        <p>As part of my "Natural Language Processing with Python" course, I implemented a heuristic algorithm for coreference resolution using Python. The algorithm uses six weighted heuristics to score the likelihood of an (antecedent, pronoun) pair. The algorithm achieved a F-score of 72.3.</p>
                        <ul class="list-inline download-buttons">
                            <li>
                                <a href="files/coreference_resolution.pdf" target="_blank" class="btn btn-download btn-lg" download="coreference_resolution.pdf"><i class="fa fa-file-pdf-o fa-fw"></i> <span class="file-name">PDF</span></a>
                            </li>
                            <li>
                                <a href="https://github.com/suro119/coreference_resolution" target="_blank" class="btn btn-download btn-lg"><i class="fa fa-github fa-fw"></i> <span class="file-name">Github</span></a>
                            </li>
                        </ul>
                    </div>
                </div>
            </div>
        </div>
    </section>